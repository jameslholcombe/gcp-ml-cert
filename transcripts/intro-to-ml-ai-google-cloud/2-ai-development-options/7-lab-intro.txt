Now it’s time for some hands-on practice.
00:03
In the following lab, you’ll use the Natural Language API to analyze text.
00:08
Specifically, you’ll identify entities and analyze sentiment with code.
00:13
Before you begin, let’s briefly review the main features of the NaturalLanguage API you learned in the previous lesson: You can
00:20
identify entities, which are subjects in the inputted text, such as Google as a company name and Mountain View as a location.
00:30
You can identify the sentiment, which indicates emotion at both the overall document and individual subject level.
00:38
You can analyze syntax and extract linguistic information such as the relationship between words.
00:46
And you can also classify the text to categories based on topics or keywords, similar to assigning a tag to a piece of text.
00:55
You perform all of this analysis through a UI, which is a quick and efficient way to demonstrate and test these features.
01:01
However, if you want to incorporate these features in production, you must embed the APIs into code.
01:09
Using APIs in your code is similar to ordering a sandwich at a deli: you order
01:12
from the menu and get your food without worrying about how it was made in the kitchen.
01:18
The same concept applies to using APIs; you only need to know three things: the features (the menu), the input (the order), and the output (the sandwich).
01:31
Like a menu, features are the types of requests that you can make to the Natural Language API.
01:37
Like a food order, the input is how how you construct the requests.
01:41
Then, the sandwich you receive after you place the order is the response (or output).
01:47
With this, you can determine next steps.
01:50
So, what are different types of requests that you can make?
01:54
The Natural Language API provides several methods for performing analysis and annotation on your text.
02:01
You’ll practice with most of them in the lab.
02:04
For entity analysis, you can use the analyzeEntities method.
02:08
The sentiment analysis is performed through the analyzeSentiment method at the entire text level, and analyzeEntitySentiment at the individual entity and subject level.
02:19
The syntactic analysis is performed with the analyzeSyntax method.
02:23
And the content classification is performed by using the classifyText method.
02:29
Now, how do you construct those requests?
02:32
The Natural Language API is a REST API and consists of JSON requests and responses.
02:38
A simple JSON request for entity analysis looks like the code shown here, where you define: The type of the document, for
02:45
example, plain text The language, like EN, which stands for English The content, which can be the text itself or the file
02:55
location in Cloud Storage, and finally, The encoding type like UTF8 After you construct the request, you need to call the API,
03:05
just like after you decide what you want at a deli, you then need to place the order with the counter person.
03:12
Here is an example to call the API with cURL.
03:15
cURL stands for Client URL and is a command line tool to transfer data between client and server.
03:22
You can also use other programming languages such as Python and Java SDKs to call the APIs.
03:28
Typically, the vendors of the product and services you are using define the APIs and provide the SDKs in different languages for you to choose.
03:38
In this example, you call the Natural Language API feature, analyzeEntites, pass the request.json file that you just constructed, and save the response to result.json file.
03:51
Finally, how should you handle the responses?
03:54
You can review the result by using a command like cat result.json or parse it for further usage.
04:02
Equipped with the technical details, in this lab you’ll use the Natural language API to: Extract entities.
04:09
Analyze sentiment.
04:10
And analyze syntax.
04:12
By completing the lab, you’ll get practice: Creating a Natural Language API request and calling the API with cURL.
04:20
Extracting entities and running sentiment analysis on text.
04:24
Performing linguistic analysis on text.
04:27
And creating a Natural Language API request in a different language.
04:31
Let’s start!